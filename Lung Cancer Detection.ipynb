{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Retrieve and save data locally and if possible, upload to AWS S3."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a comprehensive overview of how to pre-treat medical lung images prior to them being fed into D.L. machine.\n",
    "\n",
    "This is the outline if what will be accomplished:\n",
    "\n",
    "1. **Loading the DICOM files** and adding missing metadata.\n",
    "2. **Converting the pixel values to Hounsfield Units (HU),** and to what tissue these unit values correspond.\n",
    "3. **Resampling** to an isomorphic resolution to remove variance in scanner resolution.\n",
    "4. **3D plotting.** (Visualization is very useful to see what we are doing).\n",
    "5. **Lung segmentation.**\n",
    "6. **Normalization** that makes sense.\n",
    "7. **Zero centering** the scans."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing pkgs and determining Pat's."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import dicom\n",
    "import os\n",
    "import scipy.ndimage\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from skimage import measure, morphology\n",
    "from mpl_toolkits.mplot3d.art3d import Poly3DCollection\n",
    "\n",
    "#Some constants\n",
    "# INPUT_FOLDER = '../input/sample_images/'\n",
    "# patients = os.listdir(INPUT_FOLDER)\n",
    "# patients.sort()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Loading the DICOM files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dicom \n",
    "- de-facto file standard for medical imaging. \n",
    "- contain a lot of metadata (pixel size, how long one pixel is in every dimension in the real world)\n",
    "- pixel size/coarseness of scan differs from scan to scan (perform isomorphic resampling)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Following is code to load scan, which has multiple slices. \n",
    "This will be saved in a Python list.\n",
    "Every folder in dataset is one scan (one patient).\n",
    "One metadata field is missing, pixel size in Z direction, which is the slice thickness.\n",
    "This will be inferred and added to metadata. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Load scans in given folder path\n",
    "def load_scan(path):\n",
    "    slices = [dicom.read_file(path + '/' + s) for s in os.listdir(path)]\n",
    "    slices.sort(key = lambda x: float(x.ImagePositionPatient[2]))\n",
    "    try:\n",
    "        slice_thickness = np.abs(slices[0].ImagePositionPatient[2] - slices[1].ImagePositionPatient[2])\n",
    "    except:\n",
    "        slice_thickness = np.abs(slices[0]).SliceLocation - slices[1].SliceLocation\n",
    "    \n",
    "    for s in slices:\n",
    "        s.SliceThickness = slice_thickness\n",
    "                                        \n",
    "    return slices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Converting the pixel values to Hounsfield Units (HU)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The unit of measurement in CT scans is **Hounsfield Unit (HU)** which is the measurement of radiodensity. CT scanners are carefully calibrated to accurately measure this. \n",
    "\n",
    "By default though, the returned values are not in this unit. This can be fixed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some scanners have cylindrical scanning bounds, but the output image is square. The pixels that fall outside of these bounds get the fixed value -2000. This will be set to 0, which corresponds to air. \n",
    "\n",
    "Getting back to HU units, we will multiply with rescale slope and adding the intercept (which is stored in metadata of the scans)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_pixels_hu(slices):\n",
    "    image = np.stack([s.pixel_array for s in slices])\n",
    "    #Convert to int16 (from sometimes int16),\n",
    "    #should be possible as values should always be low enough (<32k)\n",
    "    image = image.astype(np.int16)\n",
    "    \n",
    "    #Set outside-of-scan pixels to 0\n",
    "    #The intercept is usually -1024, so air is approximately 0\n",
    "    image[image == -2000] = 0\n",
    "    \n",
    "    #Convert to Hounsfield units (HU)\n",
    "    for slice_number in range(len(slices)):\n",
    "        \n",
    "        intercept = slices[slice_number].RescaleIntercept\n",
    "        slope = slices[slice_number].RescaleSlope\n",
    "        \n",
    "        if slope != 1:\n",
    "            image[slice_number] = slope * image[slice_number].astype(np.float64)\n",
    "            image[slice_number] = image[slice_number].astype(np.int16)\n",
    "            \n",
    "        image[slice_number] += np.int16(intercept)\n",
    "    \n",
    "    return np.array(image, dtype=np.int16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Taking a look at one of the patients:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "first_patient = load_scan(INPUT_FOLDER + patients[0])\n",
    "first_patient_pixels = get_pixels_hu(first_patient)\n",
    "plt.hist(first_patient_pixels.flatten(), bins = 80, color = 'c')\n",
    "plt.xlabel(\"Hounsfield Units (HU)\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.show()\n",
    "\n",
    "# #Show some slice in the middle\n",
    "plt.imshow(first_patient_pixels[80], cmp=plt.cm.gray)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "first_patient = load_scan(INPUT_FOLDER + patients[0])\n",
    "first_patient_pixels = get_pixels_hu(first_patient)\n",
    "plt.hist(first_patient_pixels.flatten(), bins = 80, color = 'c')\n",
    "plt.xlabel(\"Hounsfield Units (HU)\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.show()\n",
    "\n",
    "# #Show slice in the middle\n",
    "plt.imshow(first_patient_pixels[80], cmap=plt.cm.gray)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on Hounsfield Units and this histogram, clearly see which pixels are air and which are tissue. This will be used for lung segmentation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Resampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is so that the full dataset has the same isotropic resolution between images.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If choosing to resample everything to 1mm x 1mm x 1mm, can use 3d ConvNets without having concern about learning zoom/slice thickness \n",
    "variability. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Though simple in plan, harder to code since there are some edge cases. However, following code flattens all images to the same dimensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def resample(image, scan, new_spacing = [1,1,1]):\n",
    "    \n",
    "    #Determine the current pixel spacing\n",
    "    \n",
    "    spacing = np.array([scan[0].SliceThickeness] + scan[0].PixelSpacing, dtype=np.float32)\n",
    "    \n",
    "    resize_factor = spacing/new_spacing\n",
    "    new_real_shape = image.shape * resize_factor\n",
    "    new_shape = np.round(new_real_shape)\n",
    "    real_resize_factor = new_shape / image.shape\n",
    "    new_spacing = spacing / real_resize_factor\n",
    "    \n",
    "    image = scipy.ndimage.interpolation.zoom(image, real_resize_factor, mode='nearest')\n",
    "    \n",
    "    return image, new_spacing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When using this, remember to save the new spacing!\n",
    "(The script picks the best spacing with rounding)\n",
    "\n",
    "Now, let's resample patient's pixels to dimensions: 1mm x 1mm x 1mm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pix_resampled, spacing = resample(first_patient_pixels, first_patient, [1,1,1])\n",
    "print(\"Shape before resampling\\t\", first_patient_pixels.shape)\n",
    "print(\"Shape after resampling\\t\", pix_resampled.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 3D Plotting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For visualization, it is useful to show a 3D image of the scan. \n",
    "Using marching cubes to create an approximate mesh for 3D object,\n",
    "and plot this with matplotlib.\n",
    "This is not the most efficient, but it is the best for now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_3d(image, threshold=-300):\n",
    "    \n",
    "    #Position the scan upright,\n",
    "    #so the head of the patient would be at the top facing the camera\n",
    "    p = image.transpose(2,1,0)\n",
    "    \n",
    "    verts, faces = measure.mearching_cubes(p, threshold)\n",
    "    \n",
    "    fig = plt.figure(figsize=(10,10))\n",
    "    ax = fig.add_subplot(111,projection='3d')\n",
    "    \n",
    "    #Fancy indexing: 'verts[faces]' to generate a collection of triangles\n",
    "    mesh = Poly3DCollection(verts[faces], alpha=0.70)\n",
    "    face_color = [0.45, 0.45, 0.75]\n",
    "    mesh.set_facecolor(face_color)\n",
    "    ax.add_collection3d(mesh)\n",
    "    \n",
    "    ax.set_xlim(0, p.shape[0])\n",
    "    ax.set_ylim(0, p.shape[1])\n",
    "    ax.set_zlim(0, p.shape[2])\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our plot function has a threshold argument that we can use to plot certain structures, such as all the tissue or in the case we have below, just the bones. In order to determine which structure to plot, refer to the Hounsfield units table mentioned above. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# plot_3d(pix_resampled, 400)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Lung segmentazation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to reduce the noise and focus on the tissue we want to analyze/visualize, we can segment the lungs (and tissue around it). \n",
    "\n",
    "The method used consists of a series of applications of region growing and morphological operations. In this case, we use connected component analysis. \n",
    "\n",
    "The steps are:\n",
    "\n",
    "* Threshold the image (-320 HU is a good threshold, but it does not matter much for this approach).\n",
    "* Perform connected components, determine label of air around person, fill this with 1s in the binary image.\n",
    "* Option: For every axial slice in the scan, determine the largest solid connected component (the body + air around the person), set others equal to 0. This fills the structures in the lungs in the mask.\n",
    "* Only keep the largest air pocket (the human body has other air pockets here and there)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def largest_label_volume(im, bg=-1):\n",
    "    vals, counts = np.unique(im, return_counts=True)\n",
    "    \n",
    "    counts = counts[vals != bg]\n",
    "    vals = vals[vals != bg]\n",
    "    \n",
    "    if len(counts) > 0:\n",
    "        return vals[np.argmax(counts)]\n",
    "    else:\n",
    "        return None\n",
    "    \n",
    "def segment_lung_mask(image, fill_lung_structures=True):\n",
    "    \n",
    "    #not actually binary, but 1 and 2.\n",
    "    #0 is treated as background, which we do not want\n",
    "    \n",
    "    binary_image = np.array(image > -320, dtype=mp.int8) + 1\n",
    "    labels = measure.label(binary_image)\n",
    "    \n",
    "    # Pick the pixel in the very corner to determine which label is air.\n",
    "    # Improvement: Pick multiple background labels from around the patient\n",
    "    # More resistant to \"trays\" on which the patient lays cutting the air\n",
    "    # around the person in half\n",
    "    background_label = labels[0,0,0]\n",
    "    \n",
    "    #Fill the air around the person\n",
    "    binary_image[background_label == labels] = 2\n",
    "    \n",
    "    #Method of filling the lung structures (that is better than morphological closing)\n",
    "    if fill_lung_structures:\n",
    "        #For every slice we determine the largest solid structure\n",
    "        for i, axial_slice in enumerate(binary_image):\n",
    "            axial_slice = axial_slice - 1\n",
    "            labeling = measure.label(axial_slice)\n",
    "            l_max = largest_label_volume(labeling, bg = 0)\n",
    "            \n",
    "            if l_ma is not None: #This slice contains some lung \n",
    "                binary_image[i][labeling != l_max] = 1\n",
    "                \n",
    "    binary_image -= 1 #Make the image actual binary\n",
    "    binary_image = 1-binary_image #Invert it, lungs are now 1\n",
    "    \n",
    "    #Remove other air pockets inside the body\n",
    "    labels = measure.label(binary_image, background = 0)\n",
    "    l_max = largest_label_volume(labels, bg=0)\n",
    "    if l_max is not None: #There are air pockets\n",
    "        binary_image[labels != l_max] = 0\n",
    "    \n",
    "    \n",
    "    return binary_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "segmented_lungs = segment_lung_mask(pix_resampled, False)\n",
    "segmented_lungs_fill = segment_lung_mask(pix_resampled, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plot_3d(segmented_lungs, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One thing to improve on here is to include structures within the lungs. We do not want just air in the lungs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plot_3d(segmented_lungs_fill, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is much better. We can also visualize the difference between the last two lungs shown."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_3d(segmented_lungs_fill - segmented_lungs, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pretty awesome!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When wanting to use this mask, remember to **first apply a dilation morphological operation** on it (i.e. with a circular kernel). This will expand the mask in all directions. The air + structures in the lung will not contain all the nodules. Those on the side, which is where the nodules appear most will be particularly missed. So expand the mask a little bit!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**This segmentation may fail for some edge cases.** This is because this method relies on the air outside of the patient not being connected with the air that is inside the lungs. If the patient has had a tracheostomy, this will not be the case. I am unsure if this data type is present in the dataset. Also, for noisy images such as those including a pacemaker, this method will not work. In this situation, the second largest air pocket in the body will be segmented. Check the fraction of the image that the mask corresponds to, which should be small in this case. One thing you can do in this situation is to first apply a morphological closing operation with a kernel a few mm in size to close these holes. An alternative to this would be to not use the mask at all to simplify things."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The values we have for substances in our images currently range from -1024 to around 2000. Anything above 400 is not relevant for our study since these ares simply bones with different radiodensity. A good treshold to normalize between is: -1000 and 400. The following codes for this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "MIN_BOUND = -1000.0\n",
    "MAX_BOUND = 400.0\n",
    "\n",
    "def normalize(image):\n",
    "    image = (image - MIN_BOUND) / (MAX_BOUND - MIN_BOUND)\n",
    "    image[image>1] = 1.\n",
    "    image[image<0] = 0.\n",
    "    return image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zero Centering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The final step to this preprocessing is to center the data to zero so that the mean = 0. This is done by subtracting all pixels from the mean pixel value. \n",
    "\n",
    "To determine this mean, average all images in the whole dataset.\n",
    "\n",
    "**Warning: Do not zero center with the mean per image, which has been done. CT scanners are calibrated to return acccurate HU measurements. Lower contrast or brightness for does not exist for these images though they exist for normal images, but this is not what is comprised of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "PIXEL_MEAN = 0.25 #pre-calculated from LUNA16 competition\n",
    "\n",
    "def zero_center(image):\n",
    "    image = image - PIXEL_MEAN\n",
    "    return image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NEXT: Images are now ready to be fed into CNN / other ML method. =)\n",
    "Recommended to do these steps offline since it takes a while to process these images. It may take overnight. Remember to save your results! Lastly, right after loading, do normalization and zero centering in order to save storage space."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
