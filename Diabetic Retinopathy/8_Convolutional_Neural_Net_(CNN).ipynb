{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.callbacks import TensorBoard\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.models import Sequential\n",
    "from keras.utils import np_utils\n",
    "from keras.utils import multi_gpu_model\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1337)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(X, y, test_data_size):\n",
    "    \"\"\"Split data into test and training datasets\n",
    "    \n",
    "    INPUT\n",
    "        X: Numpy array of arrays\n",
    "        y: Pandas series, which are the labels for input array X\n",
    "        test_data_size: size of test/train split. Value from 0 to 1.\n",
    "        \n",
    "    OUTPUT\n",
    "        Four array: X_train, X_test, y_train, y_test\n",
    "    \"\"\"\n",
    "    return train_test_split(X, y, test_size=test_data_size, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reshape_data(arr, img_rows, img_cols, channels):\n",
    "    \"\"\"\n",
    "    Reshapes the data into format for CNN.\n",
    "    \n",
    "    INPUT\n",
    "        arr: Array of NumPy arrays\n",
    "        img_rows: Image height\n",
    "        img_cols: Image width\n",
    "        channels: Specify if the image is grayscale (1) or RGB (3)\n",
    "        \n",
    "    OUTPUT\n",
    "        Reshaped array of Numpy arrays\n",
    "    \"\"\"\n",
    "    return arr.reshape(arr.shape[0], img_rows, img_cols, channels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cnn_model(X_train, y_train, kernel_size, nb_filters, channels, nb_epoch, batch_size, nb_classes, nb_gpus):\n",
    "    \"\"\"\n",
    "    Define and run the Convolutional Neural Network\n",
    "    \n",
    "    INPUT\n",
    "        X_train: Array of NumPy arrays\n",
    "        X_test: Array of NumPy arrays\n",
    "        Y_train: Array of labels\n",
    "        Y_test: Array of labels\n",
    "        kernel_size: Initial size of kernel\n",
    "        nb_filters: Initial number of filters\n",
    "        channels: Specify if the image is grayscale (1) or RGB (3)\n",
    "        nb_epoch: Number of epochs\n",
    "        batch_size: Batch size for the model\n",
    "        nb_classes: Number of classes for classification\n",
    "        \n",
    "    OUTPUT\n",
    "        Fitted CNN model\n",
    "    \"\"\"\n",
    "    \n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Conv2D(nb_filters, (kernel_size[0], kernel_size[1]),\n",
    "                     padding = 'valid',\n",
    "                     strides=1,\n",
    "                     input_shape=(img_rows, img_cols, channels), activation=\"relu\"))\n",
    "    \n",
    "    model.add(Conv2D(nb_filters, (kernel_size[0], kernel_size[1]), activation =\"relu\"))\n",
    "    \n",
    "    model.add(Conv2D(nb_filters, (kernel_size[0], kernel_size[1]), activation =\"relu\"))\n",
    "    \n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    model.add(Flatten())\n",
    "    print(\"Model flattened out to: \", model.output_shape)\n",
    "    \n",
    "    model.add(Dense(128))\n",
    "    model.add(Activation('sigmoid'))\n",
    "    model.add(Dropout(0.25))\n",
    "    \n",
    "    model.add(Dense(nb_classes))\n",
    "    model.add(Activation('softmax'))\n",
    "    \n",
    "    model = multi_gpu_model(model, gpus=nb_gpus)\n",
    "    \n",
    "    model.compile(loss='binary_crossentropy',\n",
    "                 optimizer='adam',\n",
    "                 metrics['accuracy'])\n",
    "    \n",
    "    stop = EarlyStopping(monitor='val_acc',\n",
    "                        min_delta=0.001,\n",
    "                        patience=2,\n",
    "                        verbose=0,\n",
    "                        mode='auto')\n",
    "    \n",
    "    tensor_board = TensorBoard(log_dir='./Graph', histogram_freq=0, write_graph=True, write_images=True)\n",
    "    \n",
    "    model.fit(X_train, y_train, batch_size=batch_size, epochs=nb_epoch,\n",
    "             verbose=1,\n",
    "             validation_split=0.2,\n",
    "             class_weight='auto',\n",
    "             callbacks=[stop, tensor_board])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(model, score, model_name):\n",
    "    \"\"\"\n",
    "    Saves Keras model to an h5 file, based on precision_score\n",
    "    \n",
    "    INPUT\n",
    "        model: Keras model object to be saved\n",
    "        score: Score to determine if model should be saved\n",
    "        model_name: name of model to be saved\n",
    "    \"\"\"\n",
    "    \n",
    "    if score >= 0.75\n",
    "        print(\"Saving Model\")\n",
    "        model.save(\"../models/\" + model_name + \"_recall_\" + str(round(score, 4)) + \".h5\")\n",
    "    else:\n",
    "        print(\"Model Not Saved. Score: \", score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    #Specify parameters before model is run.\n",
    "    batch_size = 512\n",
    "    nb_classes = 2\n",
    "    nb_epoch = 30\n",
    "    \n",
    "    img_rows, img_cols = 256, 256\n",
    "    channels = 3\n",
    "    nb_filters = 32\n",
    "    kernel_size = (8,8)\n",
    "    \n",
    "    #Import data \n",
    "    labels = pd.read_csv(\"../labels/trainLabels_master_256_v2.csv\")\n",
    "    X = np.load(\"../data/X_train_256_v2.npy\")\n",
    "    y = np.array([1 if l >= 1 else 0 for l in labels['level']])\n",
    "    #y = np.array(labels['level])\n",
    "    \n",
    "    print(\"Splitting data into test/train datasets\")\n",
    "    X_train, X_test, y_train, y_test = split_data(X, y, 0.2)\n",
    "    \n",
    "    print(\"Reshaping Data\")\n",
    "    X_train = reshape_data(X_train, img_rows, img_cols, channels)\n",
    "    X_test = reshape_data(X_test, img_rows, img_cols, channels)\n",
    "    \n",
    "    print(\"X_train Shape: \", X_train.shape)\n",
    "    print(\"X_test Shape: \", X_train.shape)\n",
    "    \n",
    "    input_shape = (img_rows, img_cols, channels)\n",
    "    \n",
    "    print(\"Normalizing Data\")\n",
    "    X_train = X_train.astype('float32')\n",
    "    X_train = X_test.astype('float32')\n",
    "    \n",
    "    X_train /=255\n",
    "    X_test /=255\n",
    "    \n",
    "    y_train = np.utils.to_categorical(y_train, nb_classes)\n",
    "    y_test = np.utils.to_categorical(y_test, nb_classes)\n",
    "    print(\"y_train Shape: \", y_train.shape)\n",
    "    print(\"y_test Shape: \", y_test.shape)\n",
    "    \n",
    "    print(\"Training Model\")\n",
    "    \n",
    "    model = cnn_mode(X_train, y_train, kernel_size, nb_filters, channels, nb_epoch, batch_size, \n",
    "                     nb_classes, nb_gpus=8)\n",
    "    \n",
    "    print(\"Predicting\")\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    score = model.evaluate(X_test, y_test, verbose=0)\n",
    "    print('Test score:', score[0])\n",
    "    print('Test accuracy:', score[1])\n",
    "    \n",
    "    y_test = np.argmax(y_test, axis=1)\n",
    "    y_pred = np.argmax(y_pred, axis=1)\n",
    "    \n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    \n",
    "    print(\"Precision: \", precision)\n",
    "    print(\"RecallL \", recall)\n",
    "    \n",
    "    save_mode(model=model, score=recall, model_name=\"DR_Two_Classes\")\n",
    "    print(\"Completed\")\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
