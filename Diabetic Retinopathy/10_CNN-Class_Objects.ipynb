{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "import pandas as pd\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers.covolutional import Conv2D\n",
    "from keras.models import Sequential\n",
    "from keras.utils import np_utils\n",
    "from keras.utils import multi_gpu_model\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import class_weight\n",
    "from skll.metrics import kappa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1337)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Creating EyeNet class in order to test model on data that model has not \"seen\"**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EyeNet:\n",
    "    def __init__(self):\n",
    "        self.X = None\n",
    "        self.y = None\n",
    "        self.X_train = None\n",
    "        self.X_test = None\n",
    "        self.y_train = None\n",
    "        self.y_test = None\n",
    "        self.test_data_size = None\n",
    "        self.weights = None\n",
    "        self.model = None\n",
    "        self.nb_classes = None\n",
    "        self.img_rows = 256\n",
    "        self.img_cols = 256\n",
    "        self.channels = 3\n",
    "        self.n_gpus = 8\n",
    "        \n",
    "    def split_data(self, y_file_path, X, test_data_size=0.2):\n",
    "    \"\"\"\n",
    "    Split data into test and training datasets\n",
    "    \n",
    "    INPUT\n",
    "        y_file_path: path to CSV containing labels\n",
    "        X: NumPy array of arrays\n",
    "        test_data_size: size of test/train split. Value from 0 to 1.\n",
    "        \n",
    "    OUTPUT\n",
    "        Four arrays: X_train, X_test, y_train, y_test\n",
    "    \"\"\"\n",
    "    labels = pd.read_csv(y_file_path)\n",
    "    self.X = np.load(X)\n",
    "    self.y = np.array(labels['level'])\n",
    "    self.weights = class_weight.compute_class_weight('balanced', np.unique(self.y), self.y)\n",
    "    self.test_data_size = test_data_size\n",
    "    self.X_train, self.X_test, self.y_train, self.y_test = train_test_split(self.X, self.y, \n",
    "                                                                           test.size=self.test_data_size,\n",
    "                                                                           random_state = 42)\n",
    "    \n",
    "    def reshape_data(self, img_rows, img_cols, channels, nb_classes):\n",
    "        \"\"\"\n",
    "        Reshapes arrays into format for MXNet\n",
    "        \n",
    "        INPUT\n",
    "            img_rows: Array (image) height\n",
    "            img_cols: Array (image) width\n",
    "            channels: Specify if image is grayscale (1) or RGB (3)\n",
    "            nb_classes: number of image classes/ categories\n",
    "            \n",
    "        OUTPUT\n",
    "            Reshaped array of NumPy arrays\n",
    "        \"\"\"\n",
    "        self.nb_classes = nb_classes\n",
    "        self.X_train = self.X_train.reshape(self.X_train.shape[0]), img_rows, img_cols, channels)\n",
    "        self.X_train = self.X_train.astype(\"float32\")\n",
    "        self.X_train /= 255\n",
    "        \n",
    "        self.y_train = np_utils.to_categorical(self.y_train, self.nb_classes)\n",
    "        \n",
    "        self.X_test = self.X_test.reshape(self.X_test.shape[0]), img_rows, img_cols, channels)\n",
    "        self.X_test = self.X_test.astype(\"float32\")\n",
    "        self.X_test /= 255\n",
    "        \n",
    "        self.y_test = np_utils.to_categorical(self.y_test, self.nb_classes)\n",
    "        \n",
    "        print(\"X_train Shape: \", self.X_train.shape)\n",
    "        print(\"X_test Shape: \", self.X_test.shape)\n",
    "        print(\"y_train Shape: \", self.y_train.shape)\n",
    "        print(\"y_test Shape: \", self.y_test.shape)\n",
    "        \n",
    "    def cnn_model(self, nb_filters, kernel_size, batch_size, nb_epoch):\n",
    "        \"\"\"\n",
    "        Define and run the convolutional neural network\n",
    "        \n",
    "        \n",
    "        \"\"\"\n",
    "        \n",
    "        self.model = Sequential()\n",
    "    \n",
    "        self.model.add(Conv2D(nb_filters, (kernel_size[0], kernel_size[1]),\n",
    "                     padding = 'valid',\n",
    "                     strides=1,\n",
    "                     input_shape=(self.img_rows, self.img_cols, self.channels), activation=\"relu\"))\n",
    "    \n",
    "        self.model.add(Conv2D(nb_filters, (kernel_size[0], kernel_size[1]), activation=\"relu\"))\n",
    "        \n",
    "        self.model.add(Conv2D(nb_filters, (kernel_size[0], kernel_size[1]), activation=\"relu\")) \n",
    "    \n",
    "    \n",
    "        self.model.add(MaxPooling2D(pool_size=(8,8)))\n",
    "    \n",
    "        self.model.add(Flatten())\n",
    "        print(\"Model flattened out to: \", self.model.output_shape)\n",
    "    \n",
    "        self.model.add(Dense(2048, activation='relu'))\n",
    "        self.model.add(Dropout(0.25))\n",
    "    \n",
    "    \n",
    "        self.model.add(Dense(2048, activation='relu'))\n",
    "        self.model.add(Dropout(0.25))\n",
    "    \n",
    "        self.model.add(Dense(nb_classes), activation('softmax'))\n",
    "    \n",
    "\n",
    "        self.model = multi_gpu_model(self.model, gpus=self.n_gpus)\n",
    "    \n",
    "        self.model.compile(loss='categorical_crossentropy',\n",
    "                 optimizer='adam',\n",
    "                 metrics['accuracy'])\n",
    "    \n",
    "        stop = EarlyStopping(monitor='val_acc',\n",
    "                        min_delta=0.001,\n",
    "                        patience=2,\n",
    "                        verbose=0,\n",
    "                        mode='auto')\n",
    "    \n",
    "        self.model.fit(self.X_train, self.y_train, batch_size=batch_size, \n",
    "            epochs=nb_epoch,\n",
    "             verbose=1,\n",
    "             validation_split=0.2,\n",
    "             class_weight=weights,\n",
    "             callbacks=[stop])\n",
    "        \n",
    "        return self.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(self):\n",
    "    \"\"\"\n",
    "    Predict the model output, and computes precision, recall, and F1 score\n",
    "    \n",
    "    INPUT\n",
    "        model: Model trained in Keras\n",
    "        \n",
    "    OUPUT\n",
    "        Precision, Recall, and F1 Score\n",
    "        \n",
    "    \"\"\"\n",
    "    predictions = self.model.predict(self.X_test)\n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "    \n",
    "    #predictions[predictions >= 1] = 1 #Remove this when non-binary classifier used\n",
    "    \n",
    "    self.y_test = np.argmax(self.y_test, axis=1)\n",
    "    \n",
    "    precision = precision_score(self.y_test, predictions, average=\"micro\")\n",
    "    recall = recall_score(self.y_test, predictions, average=\"micro\")\n",
    "    f1 = f1_score(self.y_test, predictions, average=\"micro\")\n",
    "    cohen_kappa = cohen_kappa_score(self.y_test, predictions)\n",
    "    quad_kappa = kappa(self.y_test, predictions, weights='quadratic')\n",
    "    return precision, recall, f1, cohen_kappa, quad_kappa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(self, score, model_name):\n",
    "    \"\"\"\n",
    "    Saves the model, based on scoring criteria input.\n",
    "    \n",
    "    INPUT\n",
    "        score: Scoring metric used to save model or not\n",
    "        model_name: name for the model to be saved\n",
    "        \n",
    "    OUTPUT\n",
    "        Saved model, based on scoring criteria input.\n",
    "        \n",
    "    \"\"\"\n",
    "    if score >= 0.75:\n",
    "        print(\"Saving Model\")\n",
    "        self.model.save(\"../models/\" + model_name + \"_recall_\" + str(round(score, 4)) + \".h5\")\n",
    "    else:\n",
    "        print(\"Model Not Saved. Score: \", score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    cnn = EyeNet()\n",
    "    cnn.split_data(y_file_path=\"../labels/trainLabels_master_256_v2.csv\", X=\"../data/X_train_256_v2.npy\")\n",
    "    cnn.reshape_data(img_rows=256, img_cols=256, channels=3, nb_classes=5)\n",
    "    model = cnn.cnn_model(nb_filters=32, kernel_size(4,4), batch_size=512, nb_epoch=50)\n",
    "    precision, recall, f1, cohen_kappa, quad_kappa = cnn.predict()\n",
    "    print(\"Precision: \", precision)\n",
    "    print(\"Recall: \", recall)\n",
    "    print(\"F1: \", f1)\n",
    "    print(\"Cohen Kappa Score\", cohen_kappa)\n",
    "    print(\"Quadratic Kappa: \", quad_kappa)\n",
    "    cnn.save_model(score=recall, model_name=\"DR_Class\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
