# Projects
:memo: NLP, :robot: Machine Learning in business context

Pt 1: Exploratory Data Analysis and Text Cleaning /n
Pt 2: Text Cleaning, Word Freq Through Art, Count Vectorizing on Corpus and sparse matrix turned into dense one
Pt 3: Text Cleaning cont'd/finished, Zip's Law, Scattertext (Jason Kessler's PyData 2017), Bokeh rep of each sent word freq
Pt 4: Train, Dev, Test Split, reason for Dev (justification in size of data set), different classification methods used to determine how good model is, n-grams, model performance metrics: Precision, Recall, F1, Experimenting with removing Stop Words, varying vocabulary size and n-grams
Pt 5: Tf-Idf Vectorizer (vary vocab size, vary n-grams), test multiple text class models, Lexical Approach
Pt 6: Doc2Vec

      prerequisite: Gensim

      pip install gensim
      DBOW (Distributed Bag of Words)
      DMC (Distributed Memory Concatenated)
      DMM (Distributed Memory Mean)
      DBOW + DMC
      DBOW + DMM
Pt 7: Phrase Modeling + Doc2Vec 
Pt 8: Dimensionality Reduction: chi sq with Tf-Idf vectors and PCA with document vectors extracted from Doc2Vec
Pt 9: Tf-Idf vectors fed into Neural Networks: Keras wrapped on top of Tensorflow; different model optimizations tried
Pt 10: Neural Network with Doc2Vec/Word2Vec/GloVe
Pt 11: Convolutional Neural Network with Word2Vec
